{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Setup:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "url = 'https://www.sharkattackfile.net/spreadsheets/GSAF5.xls'\n",
    "df = pd.read_excel(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head:\n",
      "          Date    Year        Type    Country              State  \\\n",
      "0  15 Mar 2024  2024.0  Unprovoked  AUSTRALIA         Queensland   \n",
      "1  04 Mar 2024  2024.0  Unprovoked        USA             Hawaii   \n",
      "2  02 Mar-2024  2024.0  Unprovoked        USA             Hawaii   \n",
      "3  25 Feb-2024  2024.0  Unprovoked  AUSTRALIA  Western Australia   \n",
      "4  14 Feb-2024  2024.0  Unprovoked      INDIA        Maharashtra   \n",
      "\n",
      "                           Location  Activity                 Name Sex  Age  \\\n",
      "0                     Bargara Beach  Swimming       Brooklyn Sauer   F   13   \n",
      "1                Old Man's, Waikiki   Surfing        Matthew White   M  NaN   \n",
      "2                    Rainbows, Oahu  Swimming                  NaN   F   11   \n",
      "3        Sandlnd Island, Jurian Bay       NaN               female   F   46   \n",
      "4  Vaitarna River, Palghar District   Fishing  Vicky Suresh Govari   M   32   \n",
      "\n",
      "   ...        Species                      Source  pdf href formula href  \\\n",
      "0  ...     Tiger shark      Yahoo News, 3/15/2024  NaN          NaN  NaN   \n",
      "1  ...  Tiger shark 8'          Surfer, 3/6/2024F  NaN          NaN  NaN   \n",
      "2  ...  3' to 4' shark  Hawaii News Now, 3/4/2024  NaN          NaN  NaN   \n",
      "3  ...     Tiger shark        WA Today, 2/26/2024  NaN          NaN  NaN   \n",
      "4  ...  Bull shark, 7'  Times of India, 2/14/2024  NaN          NaN  NaN   \n",
      "\n",
      "  Case Number Case Number.1 original order Unnamed: 21 Unnamed: 22  \n",
      "0         NaN           NaN            NaN         NaN         NaN  \n",
      "1         NaN           NaN            NaN         NaN         NaN  \n",
      "2         NaN           NaN            NaN         NaN         NaN  \n",
      "3         NaN           NaN            NaN         NaN         NaN  \n",
      "4         NaN           NaN            NaN         NaN         NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6969 entries, 0 to 6968\n",
      "Data columns (total 23 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Date            6944 non-null   object \n",
      " 1   Year            6942 non-null   float64\n",
      " 2   Type            6926 non-null   object \n",
      " 3   Country         6894 non-null   object \n",
      " 4   State           6462 non-null   object \n",
      " 5   Location        6379 non-null   object \n",
      " 6   Activity        6358 non-null   object \n",
      " 7   Name            6724 non-null   object \n",
      " 8   Sex             6365 non-null   object \n",
      " 9   Age             3950 non-null   object \n",
      " 10  Injury          6909 non-null   object \n",
      " 11  Unnamed: 11     6382 non-null   object \n",
      " 12  Time            3418 non-null   object \n",
      " 13  Species         3812 non-null   object \n",
      " 14  Source          6925 non-null   object \n",
      " 15  pdf             6799 non-null   object \n",
      " 16  href formula    6819 non-null   object \n",
      " 17  href            6796 non-null   object \n",
      " 18  Case Number     6798 non-null   object \n",
      " 19  Case Number.1   6797 non-null   object \n",
      " 20  original order  6799 non-null   float64\n",
      " 21  Unnamed: 21     1 non-null      object \n",
      " 22  Unnamed: 22     2 non-null      object \n",
      "dtypes: float64(2), object(21)\n",
      "memory usage: 1.2+ MB\n",
      "\n",
      "describe:\n",
      "              Year  original order\n",
      "count  6942.000000     6799.000000\n",
      "mean   1934.403342     3401.152081\n",
      "std     272.920956     1963.076319\n",
      "min       0.000000        2.000000\n",
      "25%    1947.000000     1701.500000\n",
      "50%    1985.000000     3401.000000\n",
      "75%    2009.000000     5100.500000\n",
      "max    2024.000000     6802.000000\n",
      "\n",
      "columns:\n",
      "['Date', 'Year', 'Type', 'Country', 'State', 'Location', 'Activity', 'Name', 'Sex', 'Age', 'Injury', 'Unnamed: 11', 'Time', 'Species ', 'Source', 'pdf', 'href formula', 'href', 'Case Number', 'Case Number.1', 'original order', 'Unnamed: 21', 'Unnamed: 22']\n"
     ]
    }
   ],
   "source": [
    "# Preview of raw DataFrame:\n",
    "print(\"head:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\ninfo:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\ndescribe:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\ncolumns:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'year', 'type', 'country', 'state', 'activity', 'sex', 'age', 'fatal', 'time']\n"
     ]
    }
   ],
   "source": [
    "# DataFrame cleaning preparation:\n",
    "\n",
    "# 1. Dropping unneeded columns and duplicates:\n",
    "columns_to_drop = [\"Source\", \"Location\", \"Injury\", \"Name\", \"pdf\", \"href formula\",\n",
    "                   \"href\", \"Case Number\", \"Case Number.1\", \"original order\",\n",
    "                   \"Unnamed: 21\", \"Unnamed: 22\", \"Species \"]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# 2. Filter rows with Year > 1800 and remove unneeded 'Types':\n",
    "df = df[df[\"Year\"] > 1800]\n",
    "\n",
    "# 3. Types of shark attacks to exclude:\n",
    "undesired_types = [\"Questionable\", \"Boat\", \"Provoked\", \"Provoked \", \"?\",\n",
    "                   \"Unverified\", \"Under investigation\", \"Unconfirmed\"]\n",
    "\n",
    "df = df[~df[\"Type\"].isin(undesired_types)]\n",
    "\n",
    "# 4. Renaming and reformatting columns:\n",
    "df.columns = [col.strip().replace(\" \", \"_\").replace(\".\", \"\").lower() for col in df.columns]\n",
    "df.rename(columns={'unnamed:_11': 'fatal'}, inplace=True)\n",
    "\n",
    "# 5. Creating a copy of the original DataFrame for further manipulation\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Check:\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fatal\n",
       "n    4740\n",
       "y    1344\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning 'fatal' column:\n",
    "value_map = {'n': 'n', 'y': 'y'}\n",
    "\n",
    "df_copy['fatal'] = df_copy['fatal'].str.strip().str.lower().map(value_map)\n",
    "\n",
    "# Calculate mode:\n",
    "fatal_mode = df_copy['fatal'].mode()[0]\n",
    "\n",
    "# Replace NaNs with 'n':\n",
    "df_copy['fatal'] = df_copy['fatal'].fillna(fatal_mode)\n",
    "\n",
    "# Check:\n",
    "df_copy['fatal'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "m          4856\n",
       "f           729\n",
       "NaN         495\n",
       "unknown       4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning 'sex' column:\n",
    "df_copy['sex'] = df_copy['sex'].str.strip().str.lower()\n",
    "\n",
    "# Replace wrong values with 'unknown':\n",
    "invalid_entries = ['lli', 'm x 2', 'n', '.']\n",
    "for entry in invalid_entries:\n",
    "    df_copy['sex'] = df_copy['sex'].replace(entry, 'unknown')\n",
    "\n",
    "# Replace missing values with 'unknown':\n",
    "df_copy['sex'].fillna('unknown')\n",
    "\n",
    "# Check:\n",
    "df_copy['sex'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "Unprovoked      4937\n",
       "Invalid          546\n",
       "Watercraft       349\n",
       "Sea Disaster     234\n",
       "NaN               16\n",
       " Provoked          2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning 'type' column:\n",
    "\n",
    "# Remove 'invalid' values:\n",
    "df_copy = df_copy[df_copy['type'] != 'invalid']\n",
    "\n",
    "# Replace 'NaN' with 'unknown':\n",
    "df_copy['type'].fillna('unknown')\n",
    "\n",
    "# Check:\n",
    "df_copy['type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marc Jay\\AppData\\Local\\Temp\\ipykernel_29244\\1909213839.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_copy['time_numeric'].fillna(round(mean_time), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "time\n",
       "nan                                                                      2912\n",
       "Afternoon                                                                 181\n",
       "11h00                                                                     130\n",
       "15h00                                                                     119\n",
       "Morning                                                                   116\n",
       "                                                                         ... \n",
       "08h58                                                                       1\n",
       "After midnight                                                              1\n",
       "01h30                                                                       1\n",
       "FATAL  (Wire netting installed at local beaches after this incident.)       1\n",
       "After dusk                                                                  1\n",
       "Name: count, Length: 400, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Convert 'time' column to strings (to avoid issues with NaN when splitting)\n",
    "df_copy['time'] = df_copy['time'].astype(str)\n",
    "\n",
    "# 2. Function to validate if time is in the correct \"hhmm\" format (e.g., \"16h30\")\n",
    "def validate_time_format(time_str):\n",
    "    # Regex pattern for valid time formats like \"16h00\", \"01h50\", etc.\n",
    "    pattern = r'^\\d{2}h\\d{2}$'\n",
    "    if re.match(pattern, time_str):\n",
    "        return time_str\n",
    "    else:\n",
    "        return None  # Invalid format, will replace with mean later\n",
    "\n",
    "# 3. Apply the validation function and keep only valid times\n",
    "df_copy['time_numeric'] = df_copy['time'].apply(lambda x: x.replace('h', '') if validate_time_format(x) else None)\n",
    "\n",
    "# 4. Convert the 'time_numeric' to numeric, replacing invalid parsing with None\n",
    "df_copy['time_numeric'] = pd.to_numeric(df_copy['time_numeric'], errors='coerce')\n",
    "\n",
    "# 5. Calculate the mean time, ignoring NaNs\n",
    "mean_time = df_copy['time_numeric'].mean()\n",
    "\n",
    "# 6. Fill NaN values (both invalid format and actual NaNs) with the calculated mean time\n",
    "df_copy['time_numeric'].fillna(round(mean_time), inplace=True)\n",
    "\n",
    "# 7. Convert all values in 'time_numeric' to integers\n",
    "df_copy['time_numeric'] = df_copy['time_numeric'].astype(int)\n",
    "\n",
    "\n",
    "# Check:\n",
    "df_copy['time'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean age: 27.718184429761564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age\n",
       "NaN     2603\n",
       "17.0     167\n",
       "18.0     146\n",
       "15.0     142\n",
       "16.0     140\n",
       "        ... \n",
       "72.0       1\n",
       "84.0       1\n",
       "86.0       1\n",
       "87.0       1\n",
       "81.0       1\n",
       "Name: count, Length: 82, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning 'age' column:\n",
    "\n",
    "# Converting 'age' to numeric, setting errors to NaN:\n",
    "df_copy['age'] = pd.to_numeric(df_copy['age'], errors='coerce')\n",
    "\n",
    "# Calculating the mean age, excluding NaNs:\n",
    "age_mean = df_copy['age'].mean()\n",
    "print(f\"Mean age: {age_mean}\")\n",
    "\n",
    "# Filling missing 'age' values with the calculated mean:\n",
    "df_copy['age'].fillna(age_mean)\n",
    "\n",
    "# Rounding 'age' values to nearest whole number:\n",
    "df_copy['age'] = df_copy['age'].round(0)\n",
    "\n",
    "# Check:\n",
    "df_copy['age'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "unknown    193\n",
      "06-2015     21\n",
      "04-2017     21\n",
      "09-2017     19\n",
      "08-2014     19\n",
      "          ... \n",
      "06-1827      1\n",
      "1828-00      1\n",
      "09-1828      1\n",
      "1829-00      1\n",
      "06-1829      1\n",
      "Name: count, Length: 1684, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "def reformat_date_adjusted(date_str):\n",
    "    # Ensure the input is a string; early return for empty or NaN-like strings\n",
    "    date_str = str(date_str).strip()\n",
    "    if not date_str or date_str.lower() == 'nan':\n",
    "        return \"unknown\"\n",
    "    # Normalize the date string\n",
    "    date_str = re.sub(r'^Reported\\s+', '', date_str, flags=re.IGNORECASE)\n",
    "    date_str = re.sub(r'\\s*-\\s*|\\s+', ' ', date_str)  # Convert '-' to ' ' and collapse multiple spaces\n",
    "    # Try parsing the date with different formats\n",
    "    try:\n",
    "        # Detect format based on separators and content\n",
    "        if re.search(r'\\d{2}\\s\\w+\\s\\d{4}', date_str):  # DD MMM YYYY or DD MMMM YYYY\n",
    "            for fmt in (\"%d %b %Y\", \"%d %B %Y\"):  # Try both abbreviated and full month name formats\n",
    "                try:\n",
    "                    parsed_date = datetime.strptime(date_str, fmt)\n",
    "                    return parsed_date.strftime(\"%m-%Y\")\n",
    "                except ValueError:\n",
    "                    pass  # If one format fails, try the next\n",
    "        elif re.search(r'\\w+\\s\\d{4}', date_str):  # MMM YYYY or MMMM YYYY\n",
    "            for fmt in (\"%b %Y\", \"%B %Y\"):  # Try both abbreviated and full month name formats\n",
    "                try:\n",
    "                    parsed_date = datetime.strptime(date_str, fmt)\n",
    "                    return parsed_date.strftime(\"%m-%Y\")\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        elif re.match(r'\\d{4}$', date_str):  # YYYY only\n",
    "            return datetime.strptime(date_str, \"%Y\").strftime(\"%Y\") + \"-00\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing date '{date_str}': {e}\")\n",
    "    return \"unknown\"\n",
    "# Application of the function:\n",
    "df_copy['date'] = df_copy['date'].astype(str)\n",
    "df_copy['date'] = df_copy['date'].apply(reformat_date_adjusted)\n",
    "# Diagnostic check to review the transformation results\n",
    "print(df_copy['date'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonality function and new seasonality column\n",
    "\n",
    "def get_seasonality(formatted_date):\n",
    "    try:\n",
    "        month = int(formatted_date.split('-')[0])\n",
    "        if month in [12, 1, 2]:\n",
    "            return \"Winter\"\n",
    "        elif month in [3, 4, 5]:\n",
    "            return \"Spring\"\n",
    "        elif month in [6, 7, 8]:\n",
    "            return \"Summer\"\n",
    "        elif month in [9, 10, 11]:\n",
    "            return \"Autumn\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "df_copy['seasonality'] = df_copy['date'].apply(get_seasonality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seasonality\n",
      "Summer    30.602837\n",
      "Autumn    24.645390\n",
      "Winter    23.226950\n",
      "Spring    21.524823\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Seasonality stats\n",
    "valid_seasons_df = df_copy[df_copy['seasonality'] != \"Unknown\"]\n",
    "season_counts = valid_seasons_df['seasonality'].value_counts()\n",
    "total_count = len(valid_seasons_df)\n",
    "season_percentage = (season_counts / total_count) * 100\n",
    "\n",
    "# Check:\n",
    "df_copy['seasonality'].value_counts(dropna=False)\n",
    "print(season_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity\n",
       "Surfing                    1101\n",
       "Swimming                    932\n",
       "NaN                         502\n",
       "Spearfishing                322\n",
       "Fishing                     268\n",
       "                           ... \n",
       "Jumped into river             1\n",
       "Wreck of the USS Somers       1\n",
       "Wreck of the Tweed            1\n",
       "Wreck of the Sovereign        1\n",
       "Hilo                          1\n",
       "Name: count, Length: 1358, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace 'NaN' with 'unknown':\n",
    "df_copy['activity'].fillna('unknown')\n",
    "\n",
    "# Check:\n",
    "df_copy['activity'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>activity</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>fatal</th>\n",
       "      <th>time</th>\n",
       "      <th>time_numeric</th>\n",
       "      <th>seasonality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6737</th>\n",
       "      <td>09-1805</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>nan</td>\n",
       "      <td>1320</td>\n",
       "      <td>Autumn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6738</th>\n",
       "      <td>02-1804</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>Watercraft</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>nan</td>\n",
       "      <td>1320</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>unknown</td>\n",
       "      <td>1803.0</td>\n",
       "      <td>Sea Disaster</td>\n",
       "      <td>USA</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>nan</td>\n",
       "      <td>1320</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6740</th>\n",
       "      <td>03-1803</td>\n",
       "      <td>1803.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>nan</td>\n",
       "      <td>1320</td>\n",
       "      <td>Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6741</th>\n",
       "      <td>unknown</td>\n",
       "      <td>1802.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>nan</td>\n",
       "      <td>1320</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    year          type    country              state activity  \\\n",
       "6737  09-1805  1805.0       Invalid        USA           New York      NaN   \n",
       "6738  02-1804  1804.0    Watercraft  AUSTRALIA    New South Wales      NaN   \n",
       "6739  unknown  1803.0  Sea Disaster        USA     South Carolina      NaN   \n",
       "6740  03-1803  1803.0    Unprovoked  AUSTRALIA  Western Australia      NaN   \n",
       "6741  unknown  1802.0    Unprovoked      INDIA                NaN      NaN   \n",
       "\n",
       "      sex  age fatal time  time_numeric seasonality  \n",
       "6737    m  NaN     n  nan          1320      Autumn  \n",
       "6738  NaN  NaN     n  nan          1320      Winter  \n",
       "6739    m  NaN     n  nan          1320     Unknown  \n",
       "6740    m  NaN     n  nan          1320      Spring  \n",
       "6741  NaN  NaN     y  nan          1320     Unknown  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head()\n",
    "\n",
    "df_copy.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1834100\n",
      "5147\n"
     ]
    }
   ],
   "source": [
    "# Merging 'country' and 'state' into 'location' to preserve data and enhance precision.\n",
    "df_location = df_copy[[\"country\", \"state\"]].fillna(\"\")\n",
    "df_location[\"location\"] = df_location[\"country\"] + \", \" + df_location[\"state\"]\n",
    "df_location[\"location\"] = df_location[\"location\"].str.strip(\", \")\n",
    "df_copy = df_copy.merge(df_location[[\"country\", \"state\", \"location\"]], on = [\"country\", \"state\"])\n",
    "df_copy\n",
    "\n",
    "# Check:\n",
    "print(df_copy[['country', 'state']].duplicated().sum())\n",
    "print(df_location[['country', 'state']].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head:\n",
      "      date    year        type    country       state  activity sex   age  \\\n",
      "0  03-2024  2024.0  Unprovoked  AUSTRALIA  Queensland  Swimming   f  13.0   \n",
      "1  03-2024  2024.0  Unprovoked  AUSTRALIA  Queensland  Swimming   f  13.0   \n",
      "2  03-2024  2024.0  Unprovoked  AUSTRALIA  Queensland  Swimming   f  13.0   \n",
      "3  03-2024  2024.0  Unprovoked  AUSTRALIA  Queensland  Swimming   f  13.0   \n",
      "4  03-2024  2024.0  Unprovoked  AUSTRALIA  Queensland  Swimming   f  13.0   \n",
      "\n",
      "  fatal   time  time_numeric seasonality               location  \n",
      "0     n  16h00          1600      Spring  AUSTRALIA, Queensland  \n",
      "1     n  16h00          1600      Spring  AUSTRALIA, Queensland  \n",
      "2     n  16h00          1600      Spring  AUSTRALIA, Queensland  \n",
      "3     n  16h00          1600      Spring  AUSTRALIA, Queensland  \n",
      "4     n  16h00          1600      Spring  AUSTRALIA, Queensland  \n",
      "\n",
      "info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1834908 entries, 0 to 1834907\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   date          object \n",
      " 1   year          float64\n",
      " 2   type          object \n",
      " 3   country       object \n",
      " 4   state         object \n",
      " 5   activity      object \n",
      " 6   sex           object \n",
      " 7   age           float64\n",
      " 8   fatal         object \n",
      " 9   time          object \n",
      " 10  time_numeric  int64  \n",
      " 11  seasonality   object \n",
      " 12  location      object \n",
      "dtypes: float64(2), int64(1), object(10)\n",
      "memory usage: 182.0+ MB\n",
      "\n",
      "describe:\n",
      "               year           age  time_numeric\n",
      "count  1.834908e+06  1.306969e+06  1.834908e+06\n",
      "mean   1.986533e+03  2.638671e+01  1.326793e+03\n",
      "std    3.670710e+01  1.447547e+01  2.472173e+02\n",
      "min    1.803000e+03  1.000000e+00  3.000000e+01\n",
      "25%    1.973000e+03  1.600000e+01  1.300000e+03\n",
      "50%    2.000000e+03  2.200000e+01  1.320000e+03\n",
      "75%    2.012000e+03  3.400000e+01  1.400000e+03\n",
      "max    2.024000e+03  8.700000e+01  2.330000e+03\n",
      "\n",
      "columns:\n",
      "['date', 'year', 'type', 'country', 'state', 'activity', 'sex', 'age', 'fatal', 'time', 'time_numeric', 'seasonality', 'location']\n",
      "\n",
      "missing values:\n",
      "type          4458\n",
      "activity    120894\n",
      "sex          84967\n",
      "age         527939\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Subsequent overview of v0.5:\n",
    "# Cell to be (re)moved or updated as we refine our analysis and finalize other KPIs.\n",
    "\n",
    "print(\"head:\")\n",
    "print(df_copy.head())\n",
    "\n",
    "print(\"\\ninfo:\")\n",
    "df_copy.info()\n",
    "\n",
    "print(\"\\ndescribe:\")\n",
    "print(df_copy.describe())\n",
    "\n",
    "print(\"\\ncolumns:\")\n",
    "print(df_copy.columns.tolist())\n",
    "\n",
    "print(\"\\nmissing values:\")\n",
    "print(df_copy.isnull().sum()[df_copy.isnull().sum() > 0])\n",
    "\n",
    "# Pending Cleaning Columns: 'date', 'year', 'activity', 'country', 'state'.\n",
    "# Note on Geo Data: Considering merging 'country' and 'state' into 'location' to preserve data and enhance precision.\n",
    "\n",
    "# Upcoming in v0.6:\n",
    "# - Cleaning for 'date', 'year', 'type' and their integration.\n",
    "# - Decision pending on creating a 'location' column and its integration.\n",
    "\n",
    "# Uniform Commentary: Please keep documentation clear and accessible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
