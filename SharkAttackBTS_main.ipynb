{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initial Setup:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "url = 'https://www.sharkattackfile.net/spreadsheets/GSAF5.xls'\n",
    "df = pd.read_excel(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head:\n",
      "          Date    Year        Type    Country              State  \\\n",
      "0  15 Mar 2024  2024.0  Unprovoked  AUSTRALIA         Queensland   \n",
      "1  04 Mar 2024  2024.0  Unprovoked        USA             Hawaii   \n",
      "2  02 Mar-2024  2024.0  Unprovoked        USA             Hawaii   \n",
      "3  25 Feb-2024  2024.0  Unprovoked  AUSTRALIA  Western Australia   \n",
      "4  14 Feb-2024  2024.0  Unprovoked      INDIA        Maharashtra   \n",
      "\n",
      "                           Location  Activity                 Name Sex  Age  \\\n",
      "0                     Bargara Beach  Swimming       Brooklyn Sauer   F   13   \n",
      "1                Old Man's, Waikiki   Surfing        Matthew White   M  NaN   \n",
      "2                    Rainbows, Oahu  Swimming                  NaN   F   11   \n",
      "3        Sandlnd Island, Jurian Bay       NaN               female   F   46   \n",
      "4  Vaitarna River, Palghar District   Fishing  Vicky Suresh Govari   M   32   \n",
      "\n",
      "   ...        Species                      Source  pdf href formula href  \\\n",
      "0  ...     Tiger shark      Yahoo News, 3/15/2024  NaN          NaN  NaN   \n",
      "1  ...  Tiger shark 8'          Surfer, 3/6/2024F  NaN          NaN  NaN   \n",
      "2  ...  3' to 4' shark  Hawaii News Now, 3/4/2024  NaN          NaN  NaN   \n",
      "3  ...     Tiger shark        WA Today, 2/26/2024  NaN          NaN  NaN   \n",
      "4  ...  Bull shark, 7'  Times of India, 2/14/2024  NaN          NaN  NaN   \n",
      "\n",
      "  Case Number Case Number.1 original order Unnamed: 21 Unnamed: 22  \n",
      "0         NaN           NaN            NaN         NaN         NaN  \n",
      "1         NaN           NaN            NaN         NaN         NaN  \n",
      "2         NaN           NaN            NaN         NaN         NaN  \n",
      "3         NaN           NaN            NaN         NaN         NaN  \n",
      "4         NaN           NaN            NaN         NaN         NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6969 entries, 0 to 6968\n",
      "Data columns (total 23 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Date            6944 non-null   object \n",
      " 1   Year            6942 non-null   float64\n",
      " 2   Type            6926 non-null   object \n",
      " 3   Country         6894 non-null   object \n",
      " 4   State           6462 non-null   object \n",
      " 5   Location        6379 non-null   object \n",
      " 6   Activity        6358 non-null   object \n",
      " 7   Name            6724 non-null   object \n",
      " 8   Sex             6365 non-null   object \n",
      " 9   Age             3950 non-null   object \n",
      " 10  Injury          6909 non-null   object \n",
      " 11  Unnamed: 11     6382 non-null   object \n",
      " 12  Time            3418 non-null   object \n",
      " 13  Species         3812 non-null   object \n",
      " 14  Source          6925 non-null   object \n",
      " 15  pdf             6799 non-null   object \n",
      " 16  href formula    6819 non-null   object \n",
      " 17  href            6796 non-null   object \n",
      " 18  Case Number     6798 non-null   object \n",
      " 19  Case Number.1   6797 non-null   object \n",
      " 20  original order  6799 non-null   float64\n",
      " 21  Unnamed: 21     1 non-null      object \n",
      " 22  Unnamed: 22     2 non-null      object \n",
      "dtypes: float64(2), object(21)\n",
      "memory usage: 1.2+ MB\n",
      "\n",
      "describe:\n",
      "              Year  original order\n",
      "count  6942.000000     6799.000000\n",
      "mean   1934.403342     3401.152081\n",
      "std     272.920956     1963.076319\n",
      "min       0.000000        2.000000\n",
      "25%    1947.000000     1701.500000\n",
      "50%    1985.000000     3401.000000\n",
      "75%    2009.000000     5100.500000\n",
      "max    2024.000000     6802.000000\n",
      "\n",
      "columns:\n",
      "['Date', 'Year', 'Type', 'Country', 'State', 'Location', 'Activity', 'Name', 'Sex', 'Age', 'Injury', 'Unnamed: 11', 'Time', 'Species ', 'Source', 'pdf', 'href formula', 'href', 'Case Number', 'Case Number.1', 'original order', 'Unnamed: 21', 'Unnamed: 22']\n"
     ]
    }
   ],
   "source": [
    "# Preview of raw DataFrame:\n",
    "print(\"head:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\ninfo:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\ndescribe:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\ncolumns:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'year', 'type', 'country', 'state', 'activity', 'sex', 'age', 'fatal', 'time']\n"
     ]
    }
   ],
   "source": [
    "# DataFrame cleaning preparation:\n",
    "\n",
    "# 1. Dropping unneeded columns and duplicates:\n",
    "columns_to_drop = [\"Source\", \"Location\", \"Injury\", \"Name\", \"pdf\", \"href formula\",\n",
    "                   \"href\", \"Case Number\", \"Case Number.1\", \"original order\",\n",
    "                   \"Unnamed: 21\", \"Unnamed: 22\", \"Species \"]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# 2. Filter rows with Year > 1800 and remove unneeded 'Types':\n",
    "df = df[df[\"Year\"] > 1800]\n",
    "\n",
    "# 3. Types of shark attacks to exclude:\n",
    "undesired_types = [\"Questionable\", \"Boat\", \"Provoked\", \"Provoked \", \"?\",\n",
    "                   \"Unverified\", \"Under investigation\", \"Unconfirmed\"]\n",
    "\n",
    "df = df[~df[\"Type\"].isin(undesired_types)]\n",
    "\n",
    "# 4. Renaming and reformatting columns:\n",
    "df.columns = [col.strip().replace(\" \", \"_\").replace(\".\", \"\").lower() for col in df.columns]\n",
    "df.rename(columns={'unnamed:_11': 'fatal'}, inplace=True)\n",
    "\n",
    "# 5. Creating a copy of the original DataFrame for further manipulation\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Check:\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fatal\n",
       "n    4740\n",
       "y    1344\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning 'fatal' column:\n",
    "value_map = {'n': 'n', 'y': 'y'}\n",
    "\n",
    "df_copy['fatal'] = df_copy['fatal'].str.strip().str.lower().map(value_map)\n",
    "\n",
    "# Calculate mode:\n",
    "fatal_mode = df_copy['fatal'].mode()[0]\n",
    "\n",
    "# Replace NaNs with 'n':\n",
    "df_copy['fatal'] = df_copy['fatal'].fillna(fatal_mode)\n",
    "\n",
    "# Check:\n",
    "df_copy['fatal'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "m          4856\n",
       "f           729\n",
       "NaN         495\n",
       "unknown       4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning 'sex' column:\n",
    "df_copy['sex'] = df_copy['sex'].str.strip().str.lower()\n",
    "\n",
    "# Replace wrong values with 'unknown':\n",
    "invalid_entries = ['lli', 'm x 2', 'n', '.']\n",
    "for entry in invalid_entries:\n",
    "    df_copy['sex'] = df_copy['sex'].replace(entry, 'unknown')\n",
    "\n",
    "# Replace missing values with 'unknown':\n",
    "df_copy['sex'].fillna('unknown')\n",
    "\n",
    "# Check:\n",
    "df_copy['sex'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "Unprovoked      4937\n",
       "Invalid          546\n",
       "Watercraft       349\n",
       "Sea Disaster     234\n",
       "NaN               16\n",
       " Provoked          2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning 'type' column:\n",
    "\n",
    "# Remove 'invalid' values:\n",
    "df_copy = df_copy[df_copy['type'] != 'invalid']\n",
    "\n",
    "# Replace 'NaN' with 'unknown':\n",
    "df_copy['type'].fillna('unknown')\n",
    "\n",
    "# Check:\n",
    "df_copy['type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_values = df['time'].unique()\n",
    "# print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      date    year          type    country  \\\n",
      "0              15 Mar 2024  2024.0    Unprovoked  AUSTRALIA   \n",
      "1              04 Mar 2024  2024.0    Unprovoked        USA   \n",
      "2              02 Mar-2024  2024.0    Unprovoked        USA   \n",
      "3              25 Feb-2024  2024.0    Unprovoked  AUSTRALIA   \n",
      "4              14 Feb-2024  2024.0    Unprovoked      INDIA   \n",
      "...                    ...     ...           ...        ...   \n",
      "6737              Sep-1805  1805.0       Invalid        USA   \n",
      "6738  Reported 26-Feb-1804  1804.0    Watercraft  AUSTRALIA   \n",
      "6739           May-17-1803  1803.0  Sea Disaster        USA   \n",
      "6740              Mar-1803  1803.0    Unprovoked  AUSTRALIA   \n",
      "6741  Reported Apr-13-1802  1802.0    Unprovoked      INDIA   \n",
      "\n",
      "                  state  activity  sex  age fatal   time  \n",
      "0            Queensland  Swimming    F   13   NaN  16h00  \n",
      "1                Hawaii   Surfing    M  NaN     N    NaN  \n",
      "2                Hawaii  Swimming    F   11     N  13h30  \n",
      "3     Western Australia       NaN    F   46     N  11h30  \n",
      "4           Maharashtra   Fishing    M   32     N    NaN  \n",
      "...                 ...       ...  ...  ...   ...    ...  \n",
      "6737           New York       NaN    M  NaN   NaN    NaN  \n",
      "6738    New South Wales       NaN  NaN  NaN     N    NaN  \n",
      "6739     South Carolina       NaN    M  NaN     N    NaN  \n",
      "6740  Western Australia       NaN    M  NaN     N    NaN  \n",
      "6741                NaN       NaN  NaN  NaN     Y    NaN  \n",
      "\n",
      "[6084 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marc Jay\\AppData\\Local\\Temp\\ipykernel_33100\\3602328815.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_copy['time'].fillna(round(mean_time), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 1. Convert 'time' column to strings (to avoid issues with NaN when splitting)\n",
    "df_copy['time'] = df_copy['time'].astype(str)\n",
    "\n",
    "# 2. Function to validate if time is in the correct \"hhmm\" format (e.g., \"16h30\")\n",
    "def validate_time_format(time_str):\n",
    "    # Regex pattern for valid time formats like \"16h00\", \"01h50\", etc.\n",
    "    pattern = r'^\\d{2}h\\d{2}$'\n",
    "    if re.match(pattern, time_str):\n",
    "        return time_str\n",
    "    else:\n",
    "        return None  # Invalid format, will replace with mean later\n",
    "\n",
    "# 3. Apply the validation function and keep only valid times\n",
    "df_copy['time'] = df_copy['time'].apply(lambda x: x.replace('h', '') if validate_time_format(x) else None)\n",
    "\n",
    "# 4. Convert the 'time_numeric' to numeric, replacing invalid parsing with None\n",
    "df_copy['time'] = pd.to_numeric(df_copy['time'], errors='coerce')\n",
    "\n",
    "# 5. Calculate the mean time, ignoring NaNs\n",
    "mean_time = df_copy['time'].mean()\n",
    "\n",
    "# 6. Fill NaN values (both invalid format and actual NaNs) with the calculated mean time\n",
    "df_copy['time'].fillna(round(mean_time), inplace=True)\n",
    "\n",
    "# 7. Convert all values in 'time_numeric' to integers\n",
    "df_copy['time'] = df_copy['time'].astype(int)\n",
    "\n",
    "# Output the updated dataframe\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean age: 27.718184429761564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age\n",
       "28.0    2685\n",
       "17.0     167\n",
       "18.0     146\n",
       "15.0     142\n",
       "16.0     140\n",
       "        ... \n",
       "72.0       1\n",
       "84.0       1\n",
       "86.0       1\n",
       "87.0       1\n",
       "81.0       1\n",
       "Name: count, Length: 81, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning 'age' column:\n",
    "\n",
    "# Converting 'age' to numeric, setting errors to NaN:\n",
    "df_copy['age'] = pd.to_numeric(df_copy['age'], errors='coerce')\n",
    "\n",
    "# Calculating the mean age, excluding NaNs:\n",
    "age_mean = df_copy['age'].mean()\n",
    "print(f\"Mean age: {age_mean}\")\n",
    "\n",
    "# Filling missing 'age' values with the calculated mean:\n",
    "df_copy['age'] = df_copy['age'].fillna(age_mean)\n",
    "\n",
    "# Rounding 'age' values to nearest whole number:\n",
    "df_copy['age'] = df_copy['age'].round(0)\n",
    "\n",
    "# Check:\n",
    "df_copy['age'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "Unknown    193\n",
      "06-2015     21\n",
      "04-2017     21\n",
      "09-2017     19\n",
      "08-2014     19\n",
      "          ... \n",
      "06-1827      1\n",
      "1828-00      1\n",
      "09-1828      1\n",
      "1829-00      1\n",
      "06-1829      1\n",
      "Name: count, Length: 1684, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def reformat_date_adjusted(date_str):\n",
    "    # Ensure the input is a string; early return for empty or NaN-like strings\n",
    "    date_str = str(date_str).strip()\n",
    "    if not date_str or date_str.lower() == 'nan':\n",
    "        return \"invalid-date\"\n",
    "    # Normalize the date string\n",
    "    date_str = re.sub(r'^Reported\\s+', '', date_str, flags=re.IGNORECASE)\n",
    "    date_str = re.sub(r'\\s*-\\s*|\\s+', ' ', date_str)  # Convert '-' to ' ' and collapse multiple spaces\n",
    "    # Try parsing the date with different formats\n",
    "    try:\n",
    "        # Detect format based on separators and content\n",
    "        if re.search(r'\\d{2}\\s\\w+\\s\\d{4}', date_str):  # DD MMM YYYY or DD MMMM YYYY\n",
    "            for fmt in (\"%d %b %Y\", \"%d %B %Y\"):  # Try both abbreviated and full month name formats\n",
    "                try:\n",
    "                    parsed_date = datetime.strptime(date_str, fmt)\n",
    "                    return parsed_date.strftime(\"%m-%Y\")\n",
    "                except ValueError:\n",
    "                    pass  # If one format fails, try the next\n",
    "        elif re.search(r'\\w+\\s\\d{4}', date_str):  # MMM YYYY or MMMM YYYY\n",
    "            for fmt in (\"%b %Y\", \"%B %Y\"):  # Try both abbreviated and full month name formats\n",
    "                try:\n",
    "                    parsed_date = datetime.strptime(date_str, fmt)\n",
    "                    return parsed_date.strftime(\"%m-%Y\")\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        elif re.match(r'\\d{4}$', date_str):  # YYYY only\n",
    "            return datetime.strptime(date_str, \"%Y\").strftime(\"%Y\") + \"-00\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing date '{date_str}': {e}\")\n",
    "    return \"Unknown\"\n",
    "# Application of the function:\n",
    "df_copy['date'] = df_copy['date'].astype(str)\n",
    "df_copy['date'] = df_copy['date'].apply(reformat_date_adjusted)\n",
    "# Diagnostic check to review the transformation results\n",
    "print(df_copy['date'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonality function and new seasonality column\n",
    "\n",
    "def get_seasonality(formatted_date):\n",
    "    try:\n",
    "        month = int(formatted_date.split('-')[0])\n",
    "        if month in [12, 1, 2]:\n",
    "            return \"Winter\"\n",
    "        elif month in [3, 4, 5]:\n",
    "            return \"Spring\"\n",
    "        elif month in [6, 7, 8]:\n",
    "            return \"Summer\"\n",
    "        elif month in [9, 10, 11]:\n",
    "            return \"Autumn\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "df_copy['seasonality'] = df_copy['date'].apply(get_seasonality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seasonality\n",
      "Summer    30.602837\n",
      "Autumn    24.645390\n",
      "Winter    23.226950\n",
      "Spring    21.524823\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Seasonality stats\n",
    "valid_seasons_df = df_copy[df_copy['seasonality'] != \"Unknown\"]\n",
    "season_counts = valid_seasons_df['seasonality'].value_counts()\n",
    "total_count = len(valid_seasons_df)\n",
    "season_percentage = (season_counts / total_count) * 100\n",
    "\n",
    "print(season_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marc Jay\\AppData\\Local\\Temp\\ipykernel_33100\\1800121191.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_copy['activity'].fillna('unknown', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "activity\n",
       "Surfing                    1101\n",
       "Swimming                    932\n",
       "unknown                     502\n",
       "Spearfishing                322\n",
       "Fishing                     268\n",
       "                           ... \n",
       "Jumped into river             1\n",
       "Wreck of the USS Somers       1\n",
       "Wreck of the Tweed            1\n",
       "Wreck of the Sovereign        1\n",
       "Hilo                          1\n",
       "Name: count, Length: 1358, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace 'NaN' with 'unknown':\n",
    "df_copy['activity'].fillna('unknown', inplace=True)\n",
    "\n",
    "# Check:\n",
    "df_copy['activity'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Queensland\n",
       "1                  Hawaii\n",
       "2                  Hawaii\n",
       "3       Western Australia\n",
       "4             Maharashtra\n",
       "              ...        \n",
       "6737             New York\n",
       "6738      New South Wales\n",
       "6739       South Carolina\n",
       "6740    Western Australia\n",
       "6741              Unknown\n",
       "Name: state, Length: 6084, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace NaNs in the State column\n",
    "df[\"state\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>activity</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>fatal</th>\n",
       "      <th>time</th>\n",
       "      <th>seasonality</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03-2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>f</td>\n",
       "      <td>13.0</td>\n",
       "      <td>n</td>\n",
       "      <td>1600</td>\n",
       "      <td>Spring</td>\n",
       "      <td>AUSTRALIA, Queensland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03-2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>m</td>\n",
       "      <td>28.0</td>\n",
       "      <td>n</td>\n",
       "      <td>1320</td>\n",
       "      <td>Spring</td>\n",
       "      <td>USA, Hawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>f</td>\n",
       "      <td>11.0</td>\n",
       "      <td>n</td>\n",
       "      <td>1330</td>\n",
       "      <td>Spring</td>\n",
       "      <td>USA, Hawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02-2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>unknown</td>\n",
       "      <td>f</td>\n",
       "      <td>46.0</td>\n",
       "      <td>n</td>\n",
       "      <td>1130</td>\n",
       "      <td>Winter</td>\n",
       "      <td>AUSTRALIA, Western Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02-2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Fishing</td>\n",
       "      <td>m</td>\n",
       "      <td>32.0</td>\n",
       "      <td>n</td>\n",
       "      <td>1320</td>\n",
       "      <td>Winter</td>\n",
       "      <td>INDIA, Maharashtra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6737</th>\n",
       "      <td>09-1805</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>New York</td>\n",
       "      <td>unknown</td>\n",
       "      <td>m</td>\n",
       "      <td>28.0</td>\n",
       "      <td>n</td>\n",
       "      <td>1320</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>USA, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6738</th>\n",
       "      <td>02-1804</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>Watercraft</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>n</td>\n",
       "      <td>1320</td>\n",
       "      <td>Winter</td>\n",
       "      <td>AUSTRALIA, New South Wales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>1803.0</td>\n",
       "      <td>Sea Disaster</td>\n",
       "      <td>USA</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>unknown</td>\n",
       "      <td>m</td>\n",
       "      <td>28.0</td>\n",
       "      <td>n</td>\n",
       "      <td>1320</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>USA, South Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6740</th>\n",
       "      <td>03-1803</td>\n",
       "      <td>1803.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>unknown</td>\n",
       "      <td>m</td>\n",
       "      <td>28.0</td>\n",
       "      <td>n</td>\n",
       "      <td>1320</td>\n",
       "      <td>Spring</td>\n",
       "      <td>AUSTRALIA, Western Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6741</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>1802.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>y</td>\n",
       "      <td>1320</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>INDIA, nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6084 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    year          type    country              state  activity  \\\n",
       "0     03-2024  2024.0    Unprovoked  AUSTRALIA         Queensland  Swimming   \n",
       "1     03-2024  2024.0    Unprovoked        USA             Hawaii   Surfing   \n",
       "2     03-2024  2024.0    Unprovoked        USA             Hawaii  Swimming   \n",
       "3     02-2024  2024.0    Unprovoked  AUSTRALIA  Western Australia   unknown   \n",
       "4     02-2024  2024.0    Unprovoked      INDIA        Maharashtra   Fishing   \n",
       "...       ...     ...           ...        ...                ...       ...   \n",
       "6737  09-1805  1805.0       Invalid        USA           New York   unknown   \n",
       "6738  02-1804  1804.0    Watercraft  AUSTRALIA    New South Wales   unknown   \n",
       "6739  Unknown  1803.0  Sea Disaster        USA     South Carolina   unknown   \n",
       "6740  03-1803  1803.0    Unprovoked  AUSTRALIA  Western Australia   unknown   \n",
       "6741  Unknown  1802.0    Unprovoked      INDIA                NaN   unknown   \n",
       "\n",
       "      sex   age fatal  time seasonality                      location  \n",
       "0       f  13.0     n  1600      Spring         AUSTRALIA, Queensland  \n",
       "1       m  28.0     n  1320      Spring                   USA, Hawaii  \n",
       "2       f  11.0     n  1330      Spring                   USA, Hawaii  \n",
       "3       f  46.0     n  1130      Winter  AUSTRALIA, Western Australia  \n",
       "4       m  32.0     n  1320      Winter            INDIA, Maharashtra  \n",
       "...   ...   ...   ...   ...         ...                           ...  \n",
       "6737    m  28.0     n  1320      Autumn                 USA, New York  \n",
       "6738  NaN  28.0     n  1320      Winter    AUSTRALIA, New South Wales  \n",
       "6739    m  28.0     n  1320     Unknown           USA, South Carolina  \n",
       "6740    m  28.0     n  1320      Spring  AUSTRALIA, Western Australia  \n",
       "6741  NaN  28.0     y  1320     Unknown                    INDIA, nan  \n",
       "\n",
       "[6084 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join 'country' and 'state' into 'location' to preserve data and enhance precision.\n",
    "location = df_copy['country'].astype(str) + ', ' + df_copy['state'].astype(str)\n",
    "df_copy = df_copy.join(location.rename('location'))\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head:\n",
      "      date    year        type    country              state  activity sex  \\\n",
      "0  03-2024  2024.0  Unprovoked  AUSTRALIA         Queensland  Swimming   f   \n",
      "1  03-2024  2024.0  Unprovoked        USA             Hawaii   Surfing   m   \n",
      "2  03-2024  2024.0  Unprovoked        USA             Hawaii  Swimming   f   \n",
      "3  02-2024  2024.0  Unprovoked  AUSTRALIA  Western Australia   unknown   f   \n",
      "4  02-2024  2024.0  Unprovoked      INDIA        Maharashtra   Fishing   m   \n",
      "\n",
      "    age fatal  time seasonality                      location  \n",
      "0  13.0     n  1600      Spring         AUSTRALIA, Queensland  \n",
      "1  28.0     n  1320      Spring                   USA, Hawaii  \n",
      "2  11.0     n  1330      Spring                   USA, Hawaii  \n",
      "3  46.0     n  1130      Winter  AUSTRALIA, Western Australia  \n",
      "4  32.0     n  1320      Winter            INDIA, Maharashtra  \n",
      "\n",
      "info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6084 entries, 0 to 6741\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   date         6084 non-null   object \n",
      " 1   year         6084 non-null   float64\n",
      " 2   type         6068 non-null   object \n",
      " 3   country      6047 non-null   object \n",
      " 4   state        5686 non-null   object \n",
      " 5   activity     6084 non-null   object \n",
      " 6   sex          5589 non-null   object \n",
      " 7   age          6084 non-null   float64\n",
      " 8   fatal        6084 non-null   object \n",
      " 9   time         6084 non-null   int64  \n",
      " 10  seasonality  6084 non-null   object \n",
      " 11  location     6084 non-null   object \n",
      "dtypes: float64(2), int64(1), object(9)\n",
      "memory usage: 617.9+ KB\n",
      "\n",
      "describe:\n",
      "              year          age         time\n",
      "count  6084.000000  6084.000000  6084.000000\n",
      "mean   1973.507232    27.838757  1319.817883\n",
      "std      44.870256    10.939079   230.046651\n",
      "min    1802.000000     1.000000    30.000000\n",
      "25%    1950.000000    22.000000  1320.000000\n",
      "50%    1988.000000    28.000000  1320.000000\n",
      "75%    2009.000000    28.000000  1320.000000\n",
      "max    2024.000000    87.000000  2330.000000\n",
      "\n",
      "columns:\n",
      "['date', 'year', 'type', 'country', 'state', 'activity', 'sex', 'age', 'fatal', 'time', 'seasonality', 'location']\n",
      "\n",
      "missing values:\n",
      "type        16\n",
      "country     37\n",
      "state      398\n",
      "sex        495\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Subsequent overview of v0.5:\n",
    "# Cell to be (re)moved or updated as we refine our analysis and finalize other KPIs.\n",
    "\n",
    "print(\"head:\")\n",
    "print(df_copy.head())\n",
    "\n",
    "print(\"\\ninfo:\")\n",
    "df_copy.info()\n",
    "\n",
    "print(\"\\ndescribe:\")\n",
    "print(df_copy.describe())\n",
    "\n",
    "print(\"\\ncolumns:\")\n",
    "print(df_copy.columns.tolist())\n",
    "\n",
    "print(\"\\nmissing values:\")\n",
    "print(df_copy.isnull().sum()[df_copy.isnull().sum() > 0])\n",
    "\n",
    "# Pending Cleaning Columns: 'date', 'year', 'activity', 'country', 'state'.\n",
    "# Note on Geo Data: Considering merging 'country' and 'state' into 'location' to preserve data and enhance precision.\n",
    "\n",
    "# Upcoming in v0.6:\n",
    "# - Cleaning for 'date', 'year', 'type' and their integration.\n",
    "# - Decision pending on creating a 'location' column and its integration.\n",
    "\n",
    "# Uniform Commentary: Please keep documentation clear and accessible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
