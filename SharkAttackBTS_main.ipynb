{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Setup:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "url = 'https://www.sharkattackfile.net/spreadsheets/GSAF5.xls'\n",
    "df = pd.read_excel(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview of raw DataFrame:\n",
    "print(\"head:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\ninfo:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\ndescribe:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\ncolumns:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame cleaning preparation:\n",
    "\n",
    "# 1. Dropping unneeded columns and duplicates:\n",
    "columns_to_drop = [\"Source\", \"Location\", \"Injury\", \"Name\", \"pdf\", \"href formula\",\n",
    "                   \"href\", \"Case Number\", \"Case Number.1\", \"original order\",\n",
    "                   \"Unnamed: 21\", \"Unnamed: 22\", \"Species \"]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# 2. Filter rows with Year > 1800 and remove unneeded 'Types':\n",
    "df = df[df[\"Year\"] > 1800]\n",
    "\n",
    "# 3. Types of shark attacks to exclude:\n",
    "undesired_types = [\"Questionable\", \"Boat\", \"Provoked\", \"Provoked \", \"?\",\n",
    "                   \"Unverified\", \"Under investigation\", \"Unconfirmed\"]\n",
    "\n",
    "df = df[~df[\"Type\"].isin(undesired_types)]\n",
    "\n",
    "# 4. Renaming and reformatting columns:\n",
    "df.columns = [col.strip().replace(\" \", \"_\").replace(\".\", \"\").lower() for col in df.columns]\n",
    "df.rename(columns={'unnamed:_11': 'fatal'}, inplace=True)\n",
    "\n",
    "# 5. Creating a copy of the original DataFrame for further manipulation\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Check:\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning 'fatal' column:\n",
    "value_map = {'n': 'n', 'y': 'y'}\n",
    "\n",
    "df_copy['fatal'] = df_copy['fatal'].str.strip().str.lower().map(value_map)\n",
    "\n",
    "# Calculate mode:\n",
    "fatal_mode = df_copy['fatal'].mode()[0]\n",
    "\n",
    "# Replace NaNs with 'n':\n",
    "df_copy['fatal'] = df_copy['fatal'].fillna(fatal_mode)\n",
    "\n",
    "# Check:\n",
    "df_copy['fatal'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning 'sex' column:\n",
    "df_copy['sex'] = df_copy['sex'].str.strip().str.lower()\n",
    "\n",
    "# Replace wrong values with 'unknown':\n",
    "invalid_entries = ['lli', 'm x 2', 'n', '.']\n",
    "for entry in invalid_entries:\n",
    "    df_copy['sex'] = df_copy['sex'].replace(entry, 'unknown')\n",
    "\n",
    "# Replace missing values with 'unknown':\n",
    "df_copy['sex'].fillna('unknown', inplace=True)\n",
    "\n",
    "# Check:\n",
    "df_copy['sex'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning 'type' column:\n",
    "\n",
    "# Remove 'invalid' values:\n",
    "df_copy = df_copy[df_copy['type'] != 'invalid']\n",
    "\n",
    "# Replace 'NaN' with 'unknown':\n",
    "df_copy['type'].fillna('unknown', inplace=True)\n",
    "\n",
    "# Check:\n",
    "df_copy['type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning 'time' column:\n",
    "df_copy['time'] = df_copy['time'].astype(str)\n",
    "\n",
    "# Function to validate if time is in the correct \"hhmm\" format (e.g., \"1630\"):\n",
    "def validate_time_format(time_str):\n",
    "    # Regex pattern for valid time formats like \"1600\", \"0150\", etc.\n",
    "    pattern = r'^\\d{2}h\\d{2}$'\n",
    "    if re.match(pattern, time_str):\n",
    "        return time_str\n",
    "    else:\n",
    "        return None  # Invalid format, will replace with mean later.\n",
    "\n",
    "# Apply the function and remove 'h', replace invalid/missing times with 'None':\n",
    "df_copy['time'] = df_copy['time'].apply(lambda x: x.replace('h', '') if validate_time_format(x) else None)\n",
    "\n",
    "# Convert 'time' to numeric, keeping NaN as it is to calculate mean time later:\n",
    "df_copy['time'] = pd.to_numeric(df_copy['time'], errors='coerce')\n",
    "\n",
    "# Calculate the mean time, ignoring NaN values in the calculation:\n",
    "mean_time = int(df_copy['time'].mean(skipna=True))\n",
    "\n",
    "# Fill in missing or invalid times with the mean time calculated\n",
    "df_copy['time'].fillna(mean_time, inplace=True)\n",
    "\n",
    "# Ensure 'time' column is integer:\n",
    "df_copy['time'] = df_copy['time'].astype(int)\n",
    "\n",
    "# Check:\n",
    "df_copy['time'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning 'age' column:\n",
    "\n",
    "# Converting 'age' to numeric, setting errors to NaN:\n",
    "df_copy['age'] = pd.to_numeric(df_copy['age'], errors='coerce')\n",
    "\n",
    "# Calculating the mean age, excluding NaNs:\n",
    "age_mean = df_copy['age'].mean()\n",
    "print(f\"Mean age: {age_mean}\")\n",
    "\n",
    "# Filling missing 'age' values with the calculated mean:\n",
    "df_copy['age'].fillna(age_mean, inplace=True)\n",
    "\n",
    "# Rounding 'age' values to nearest whole number:\n",
    "df_copy['age'] = df_copy['age'].round(0)\n",
    "\n",
    "# Check:\n",
    "df_copy['age'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsequent overview of v0.5:\n",
    "# Cell to be (re)moved or updated as we refine our analysis and finalize other KPIs.\n",
    "\n",
    "print(\"head:\")\n",
    "print(df_copy.head())\n",
    "\n",
    "print(\"\\ninfo:\")\n",
    "df_copy.info()\n",
    "\n",
    "print(\"\\ndescribe:\")\n",
    "print(df_copy.describe())\n",
    "\n",
    "print(\"\\ncolumns:\")\n",
    "print(df_copy.columns.tolist())\n",
    "\n",
    "print(\"\\nmissing values:\")\n",
    "print(df_copy.isnull().sum()[df_copy.isnull().sum() > 0])\n",
    "\n",
    "# Pending Cleaning Columns: 'date', 'year', 'activity', 'country', 'state'.\n",
    "# Note on Geo Data: Considering merging 'country' and 'state' into 'location' to preserve data and enhance precision.\n",
    "\n",
    "# Upcoming in v0.6:\n",
    "# - Cleaning for 'date', 'year', 'type' and their integration.\n",
    "# - Decision pending on creating a 'location' column and its integration.\n",
    "\n",
    "# Uniform Commentary: Please keep documentation clear and accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
