{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Setup:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "url = 'https://www.sharkattackfile.net/spreadsheets/GSAF5.xls'\n",
    "df = pd.read_excel(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview of raw DataFrame:\n",
    "print(\"head:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\ninfo:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\ndescribe:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\ncolumns:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame cleaning preparation:\n",
    "\n",
    "# 1. Dropping unneeded columns and duplicates:\n",
    "columns_to_drop = [\"Source\", \"Location\", \"Injury\", \"Name\", \"pdf\", \"href formula\",\n",
    "                   \"href\", \"Case Number\", \"Case Number.1\", \"original order\",\n",
    "                   \"Unnamed: 21\", \"Unnamed: 22\", \"Species \"]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# 2. Filter rows with Year > 1800 and remove unneeded 'Types':\n",
    "df = df[df[\"Year\"] > 1800]\n",
    "\n",
    "# 3. Types of shark attacks to exclude:\n",
    "undesired_types = [\"Questionable\", \"Boat\", \"Provoked\", \"Provoked \", \"?\",\n",
    "                   \"Unverified\", \"Under investigation\", \"Unconfirmed\"]\n",
    "\n",
    "df = df[~df[\"Type\"].isin(undesired_types)]\n",
    "\n",
    "# 4. Renaming and reformatting columns:\n",
    "df.columns = [col.strip().replace(\" \", \"_\").replace(\".\", \"\").lower() for col in df.columns]\n",
    "df.rename(columns={'unnamed:_11': 'fatal'}, inplace=True)\n",
    "\n",
    "# 5. Creating a copy of the original DataFrame for further manipulation\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Check:\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning 'fatal' column:\n",
    "value_map = {'n': 'n', 'y': 'y'}\n",
    "\n",
    "df_copy['fatal'] = df_copy['fatal'].str.strip().str.lower().map(value_map)\n",
    "\n",
    "# Calculate mode:\n",
    "fatal_mode = df_copy['fatal'].mode()[0]\n",
    "\n",
    "# Replace NaNs with 'n':\n",
    "df_copy['fatal'] = df_copy['fatal'].fillna(fatal_mode)\n",
    "\n",
    "# Check:\n",
    "df_copy['fatal'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning 'sex' column:\n",
    "df_copy['sex'] = df_copy['sex'].str.strip().str.lower()\n",
    "\n",
    "# Replace wrong values with 'unknown':\n",
    "invalid_entries = ['lli', 'm x 2', 'n', '.']\n",
    "for entry in invalid_entries:\n",
    "    df_copy['sex'] = df_copy['sex'].replace(entry, 'unknown')\n",
    "\n",
    "# Replace missing values with 'unknown':\n",
    "df_copy['sex'].fillna('unknown')\n",
    "\n",
    "# Check:\n",
    "df_copy['sex'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning 'type' column:\n",
    "\n",
    "# Remove 'invalid' values:\n",
    "df_copy = df_copy[df_copy['type'] != 'invalid']\n",
    "\n",
    "# Replace 'NaN' with 'unknown':\n",
    "df_copy['type'].fillna('unknown')\n",
    "\n",
    "# Check:\n",
    "df_copy['type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_values = df['time'].unique()\n",
    "# print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert 'time' column to strings (to avoid issues with NaN when splitting)\n",
    "df_copy['time'] = df_copy['time'].astype(str)\n",
    "\n",
    "# 2. Function to validate if time is in the correct \"hhmm\" format (e.g., \"16h30\")\n",
    "def validate_time_format(time_str):\n",
    "    # Regex pattern for valid time formats like \"16h00\", \"01h50\", etc.\n",
    "    pattern = r'^\\d{2}h\\d{2}$'\n",
    "    if re.match(pattern, time_str):\n",
    "        return time_str\n",
    "    else:\n",
    "        return None  # Invalid format, will replace with mean later\n",
    "\n",
    "# 3. Apply the validation function and keep only valid times\n",
    "df_copy['time'] = df_copy['time'].apply(lambda x: x.replace('h', '') if validate_time_format(x) else None)\n",
    "\n",
    "# 4. Convert the 'time_numeric' to numeric, replacing invalid parsing with None\n",
    "df_copy['time'] = pd.to_numeric(df_copy['time'], errors='coerce')\n",
    "\n",
    "# 5. Calculate the mean time, ignoring NaNs\n",
    "mean_time = df_copy['time'].mean()\n",
    "\n",
    "# 6. Fill NaN values (both invalid format and actual NaNs) with the calculated mean time\n",
    "df_copy['time'].fillna(round(mean_time), inplace=True)\n",
    "\n",
    "# 7. Convert all values in 'time_numeric' to integers\n",
    "df_copy['time'] = df_copy['time'].astype(int)\n",
    "\n",
    "# Output the updated dataframe\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning 'age' column:\n",
    "\n",
    "# Converting 'age' to numeric, setting errors to NaN:\n",
    "df_copy['age'] = pd.to_numeric(df_copy['age'], errors='coerce')\n",
    "\n",
    "# Calculating the mean age, excluding NaNs:\n",
    "age_mean = df_copy['age'].mean()\n",
    "print(f\"Mean age: {age_mean}\")\n",
    "\n",
    "# Filling missing 'age' values with the calculated mean:\n",
    "df_copy['age'] = df_copy['age'].fillna(age_mean)\n",
    "\n",
    "# Rounding 'age' values to nearest whole number:\n",
    "df_copy['age'] = df_copy['age'].round(0)\n",
    "\n",
    "# Check:\n",
    "df_copy['age'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_date_adjusted(date_str):\n",
    "    # Ensure the input is a string; early return for empty or NaN-like strings\n",
    "    date_str = str(date_str).strip()\n",
    "    if not date_str or date_str.lower() == 'nan':\n",
    "        return \"invalid-date\"\n",
    "    # Normalize the date string\n",
    "    date_str = re.sub(r'^Reported\\s+', '', date_str, flags=re.IGNORECASE)\n",
    "    date_str = re.sub(r'\\s*-\\s*|\\s+', ' ', date_str)  # Convert '-' to ' ' and collapse multiple spaces\n",
    "    # Try parsing the date with different formats\n",
    "    try:\n",
    "        # Detect format based on separators and content\n",
    "        if re.search(r'\\d{2}\\s\\w+\\s\\d{4}', date_str):  # DD MMM YYYY or DD MMMM YYYY\n",
    "            for fmt in (\"%d %b %Y\", \"%d %B %Y\"):  # Try both abbreviated and full month name formats\n",
    "                try:\n",
    "                    parsed_date = datetime.strptime(date_str, fmt)\n",
    "                    return parsed_date.strftime(\"%m-%Y\")\n",
    "                except ValueError:\n",
    "                    pass  # If one format fails, try the next\n",
    "        elif re.search(r'\\w+\\s\\d{4}', date_str):  # MMM YYYY or MMMM YYYY\n",
    "            for fmt in (\"%b %Y\", \"%B %Y\"):  # Try both abbreviated and full month name formats\n",
    "                try:\n",
    "                    parsed_date = datetime.strptime(date_str, fmt)\n",
    "                    return parsed_date.strftime(\"%m-%Y\")\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        elif re.match(r'\\d{4}$', date_str):  # YYYY only\n",
    "            return datetime.strptime(date_str, \"%Y\").strftime(\"%Y\") + \"-00\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing date '{date_str}': {e}\")\n",
    "    return \"Unknown\"\n",
    "# Application of the function:\n",
    "df_copy['date'] = df_copy['date'].astype(str)\n",
    "df_copy['date'] = df_copy['date'].apply(reformat_date_adjusted)\n",
    "# Diagnostic check to review the transformation results\n",
    "print(df_copy['date'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonality function and new seasonality column\n",
    "\n",
    "def get_seasonality(formatted_date):\n",
    "    try:\n",
    "        month = int(formatted_date.split('-')[0])\n",
    "        if month in [12, 1, 2]:\n",
    "            return \"Winter\"\n",
    "        elif month in [3, 4, 5]:\n",
    "            return \"Spring\"\n",
    "        elif month in [6, 7, 8]:\n",
    "            return \"Summer\"\n",
    "        elif month in [9, 10, 11]:\n",
    "            return \"Autumn\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "df_copy['seasonality'] = df_copy['date'].apply(get_seasonality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonality stats\n",
    "valid_seasons_df = df_copy[df_copy['seasonality'] != \"Unknown\"]\n",
    "season_counts = valid_seasons_df['seasonality'].value_counts()\n",
    "total_count = len(valid_seasons_df)\n",
    "season_percentage = (season_counts / total_count) * 100\n",
    "\n",
    "print(season_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'NaN' with 'unknown':\n",
    "df_copy['activity'].fillna('unknown', inplace=True)\n",
    "\n",
    "# Check:\n",
    "df_copy['activity'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaNs in the State column\n",
    "df[\"state\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join 'country' and 'state' into 'location' to preserve data and enhance precision.\n",
    "location = df_copy['country'].astype(str) + ', ' + df_copy['state'].astype(str)\n",
    "df_copy = df_copy.join(location.rename('location'))\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsequent overview of v0.5:\n",
    "# Cell to be (re)moved or updated as we refine our analysis and finalize other KPIs.\n",
    "\n",
    "print(\"head:\")\n",
    "print(df_copy.head())\n",
    "\n",
    "print(\"\\ninfo:\")\n",
    "df_copy.info()\n",
    "\n",
    "print(\"\\ndescribe:\")\n",
    "print(df_copy.describe())\n",
    "\n",
    "print(\"\\ncolumns:\")\n",
    "print(df_copy.columns.tolist())\n",
    "\n",
    "print(\"\\nmissing values:\")\n",
    "print(df_copy.isnull().sum()[df_copy.isnull().sum() > 0])\n",
    "\n",
    "# Pending Cleaning Columns: 'date', 'year', 'activity', 'country', 'state'.\n",
    "# Note on Geo Data: Considering merging 'country' and 'state' into 'location' to preserve data and enhance precision.\n",
    "\n",
    "# Upcoming in v0.6:\n",
    "# - Cleaning for 'date', 'year', 'type' and their integration.\n",
    "# - Decision pending on creating a 'location' column and its integration.\n",
    "\n",
    "# Uniform Commentary: Please keep documentation clear and accessible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
